{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "369e80f5-0bbe-41c3-aa4c-6d1a34ff212b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/510210994784371', creation_time=1758028589440, experiment_id='510210994784371', last_update_time=1758200240340, lifecycle_stage='active', name='/Desarrollo_de_Soluciones/Combined_Datasets', tags={'mlflow.experiment.sourceName': '/Desarrollo_de_Soluciones/Combined_Datasets',\n",
       " 'mlflow.experimentKind': 'custom_model_development',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'j.rico566@uniandes.edu.co',\n",
       " 'mlflow.ownerId': '75126365786967'}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, f1_score, recall_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "os.environ[\"DATABRICKS_HOST\"] = \"https://dbc-e0c2984f-335b.cloud.databricks.com/\"\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = \"dapi407bc8d2e8ea23807d8c3d135876f810\"\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_experiment(\"/Desarrollo_de_Soluciones/Combined_Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "710acec1-17eb-4613-a1f9-7e070d602d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar los datos y procesar los datos\n",
    "\n",
    "data_training = pd.read_csv(\"../data/cleaned_train_dataset.csv\")\n",
    "data_test = pd.read_csv(\"../data/cleaned_test_dataset.csv\")\n",
    "data_validation = pd.read_csv(\"../data/cleaned_val_dataset.csv\")\n",
    "data_coachrane = pd.read_csv(\"../data/cochrane_sample_large.csv\")\n",
    "data_coachrane[\"label\"] = (data_coachrane[\"label\"].str.strip().str.lower().map({\"plain\": 0, \"technical\": 1}).astype(\"int8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970c8e17-6264-4fcc-a8d7-c350ee07dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar los DF\n",
    "frames = []\n",
    "for df in (data_training, data_validation, data_test):\n",
    "    frames.append(df[[\"text\", \"label\"]])\n",
    "frames.append(data_coachrane[[\"text\", \"label\"]])\n",
    "\n",
    "data_all = pd.concat(frames, ignore_index=True).dropna(subset=[\"text\", \"label\"])\n",
    "data_all[\"label\"] = data_all[\"label\"].astype(int)\n",
    "\n",
    "train_df, val_df = train_test_split(data_all, test_size=0.2, shuffle=True, random_state=42, stratify=data_all[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac29f82-f22e-40fe-a735-d384e204a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparametros de los Modelos y vectorizador\n",
    "\n",
    "tfidf_params = {\n",
    "    \"ngram_range\": (1, 2),\n",
    "    \"min_df\": 0.01,\n",
    "    \"max_features\": 10000,\n",
    "}\n",
    "\n",
    "logreg_params = {\n",
    "    \"C\": 1.0,            \n",
    "    \"solver\": \"liblinear\", \n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 400,\n",
    "    \"max_depth\": 4,\n",
    "}\n",
    "\n",
    "nb_params = {\n",
    "    \"alpha\": 0.1,\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    \"kernel\": \"linear\",\n",
    "    \"C\": 1.0,\n",
    "    \"probability\": True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736c341d-3373-47aa-b09d-c7949a0fa8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear vectores a partir de los datos\n",
    "\n",
    "vec = TfidfVectorizer(**tfidf_params)\n",
    "X_train = vec.fit_transform(train_df[\"text\"].astype(str))\n",
    "X_val   = vec.transform(val_df[\"text\"].astype(str))\n",
    "\n",
    "y_train = train_df[\"label\"].values\n",
    "y_val   = val_df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e15cf9-4b28-47c4-9690-ead8463868af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanio de la data vectorizada: 1862 muestras de 2693 dimensiones\n"
     ]
    }
   ],
   "source": [
    "print(f\"tamanio de la data vectorizada: {X_train.shape[0]} muestras de {X_train.shape[1]} dimensiones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5143ee-632e-4472-a707-454e0d628a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "\n",
    "logreg = LogisticRegression(**logreg_params)\n",
    "\n",
    "xgboost = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    **xgb_params\n",
    ")\n",
    "\n",
    "naive_bayes = MultinomialNB(alpha=nb_params[\"alpha\"])\n",
    "\n",
    "svm = SVC(**svm_params)\n",
    "\n",
    "modelos = [logreg, xgboost, naive_bayes, svm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78aaafa4-d093-48c3-baa4-581b88ad57aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_and_preds(model, X):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        s = model.predict_proba(X)[:, 1]\n",
    "        p = (s >= 0.5).astype(int)\n",
    "    else:\n",
    "        s = model.decision_function(X)\n",
    "        p = (s >= 0).astype(int)\n",
    "    return s, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0f79b98-7684-427c-8fe7-8214a6e11236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3674c7afb4c4ffea905b292b5b9498a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Combined eval:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run LogisticRegression at: https://dbc-e0c2984f-335b.cloud.databricks.com/ml/experiments/510210994784371/runs/014f5159e4d7457db1806d1764e90831\n",
      "🧪 View experiment at: https://dbc-e0c2984f-335b.cloud.databricks.com/ml/experiments/510210994784371\n",
      "🏃 View run XGBClassifier at: https://dbc-e0c2984f-335b.cloud.databricks.com/ml/experiments/510210994784371/runs/88d53df53732421397e6482233c830c5\n",
      "🧪 View experiment at: https://dbc-e0c2984f-335b.cloud.databricks.com/ml/experiments/510210994784371\n",
      "🏃 View run MultinomialNB at: https://dbc-e0c2984f-335b.cloud.databricks.com/ml/experiments/510210994784371/runs/e32b0b69e3cc4fbcbcd75fb4d6686f4e\n",
      "🧪 View experiment at: https://dbc-e0c2984f-335b.cloud.databricks.com/ml/experiments/510210994784371\n",
      "🏃 View run SVC at: https://dbc-e0c2984f-335b.cloud.databricks.com/ml/experiments/510210994784371/runs/f7aaf24bfe184aa4bb9ee030d41e1bcb\n",
      "🧪 View experiment at: https://dbc-e0c2984f-335b.cloud.databricks.com/ml/experiments/510210994784371\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(modelos, desc=\"Combined eval\", leave=True)\n",
    "for model in pbar:\n",
    "    run_name = f\"{model.__class__.__name__}\"\n",
    "    pbar.set_description(run_name)\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.set_tag(\"dataset\", \"combined_old+cochrane\")\n",
    "        mlflow.log_param(\"n_train\", int(X_train.shape[0]))\n",
    "        mlflow.log_param(\"n_val\", int(X_val.shape[0]))\n",
    "        mlflow.log_param(\"vocab_size\", int(X_train.shape[1]))\n",
    "        mlflow.log_param(\"tfidf_ngram_range\", str(tfidf_params.get(\"ngram_range\")))\n",
    "        mlflow.log_param(\"tfidf_min_df\", tfidf_params.get(\"min_df\"))\n",
    "        mlflow.log_param(\"tfidf_max_features\", tfidf_params.get(\"max_features\"))\n",
    "\n",
    "        # Entrena\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Val\n",
    "        s_val, yhat_val = get_scores_and_preds(model, X_val)\n",
    "        metrics_val = {\n",
    "            \"val_pr_auc\": float(average_precision_score(y_val, s_val)),\n",
    "            \"val_roc_auc\": float(roc_auc_score(y_val, s_val)),\n",
    "            \"val_f1\": float(f1_score(y_val, yhat_val)),\n",
    "            \"val_recall\": float(recall_score(y_val, yhat_val)),\n",
    "            \"val_accuracy\": float(accuracy_score(y_val, yhat_val)),\n",
    "        }\n",
    "        mlflow.log_metrics(metrics_val)\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cddca4ff-ad98-4965-8809-05f47180624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento Concluido con Exito!\n"
     ]
    }
   ],
   "source": [
    "print(\"Experimento Concluido con Exito!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4051f743-7d74-4aca-b5b7-c4ba1e3de730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#texto= \"The initial symptoms were similar to other viral diseases that are still extant, such as influenza and the common cold: fever of at least 38.3 °C (101 °F), muscle pain, malaise, headache and fatigue. As the digestive tract was commonly involved, nausea, vomiting, and backache often occurred. The early prodromal stage usually lasted 2–4 days. By days 12–15, the first visible lesions – small reddish spots called enanthem – appeared on mucous membranes of the mouth, tongue, palate, and throat, and the temperature fell to near-normal. These lesions rapidly enlarged and ruptured, releasing large amounts of virus into the saliva.\"\n",
    "texto = \"In contrast to earlier views on BPD, this condition can remit, and symptoms can be reduced and managed. Nevertheless, specific symptoms such as fear of abandonment, impulsivity, intense anger, and an unstable self-image may persist. Individuals with BPD may also continue to experience impairments in social and occupational functioning and may have a need for ongoing treatment. Rates of suicide attempts and episodes of self-harm also decline over time, but they continue to occur more often than in individuals without BPD. Furthermore, in longitudinal studies, BPD is associated with increases in deaths due to suicide as well as with all-cause mortality. Thus, the lifetime burden and psychosocial impairment associated with BPD can be substantial because it typically has an onset in adolescence or early adulthood and can persist for many years. In addition, individuals with BPD experience increases in health care costs related to BPD and to other physical conditions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05aaf1a2-e272-4f94-841b-7e79aee5f676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segun LogisticRegression el texto es technical\n",
      "segun XGBClassifier el texto es technical\n",
      "segun MultinomialNB el texto es technical\n",
      "segun SVC el texto es technical\n"
     ]
    }
   ],
   "source": [
    "vector = vec.transform([texto.lower()])\n",
    "preds = [clf.predict(vector) for clf in modelos]\n",
    "\n",
    "inv_map = {0: \"plain\", 1: \"technical\"}\n",
    "for clf, pred in zip(modelos, preds):\n",
    "    label = int(pred[0])      # o: pred.item()\n",
    "    print(f\"segun {clf.__class__.__name__} el texto es {inv_map[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75ed3cf8-6dd3-4b7b-b897-8c3ddeaa2aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build\\lib\n",
      "creating build\\lib\\textclf_logreg\n",
      "copying textclf_logreg\\__init__.py -> build\\lib\\textclf_logreg\n",
      "running egg_info\n",
      "creating textclf_logreg.egg-info\n",
      "writing textclf_logreg.egg-info\\PKG-INFO\n",
      "writing dependency_links to textclf_logreg.egg-info\\dependency_links.txt\n",
      "writing requirements to textclf_logreg.egg-info\\requires.txt\n",
      "writing top-level names to textclf_logreg.egg-info\\top_level.txt\n",
      "writing manifest file 'textclf_logreg.egg-info\\SOURCES.txt'\n",
      "reading manifest file 'textclf_logreg.egg-info\\SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "writing manifest file 'textclf_logreg.egg-info\\SOURCES.txt'\n",
      "copying textclf_logreg\\model.joblib -> build\\lib\\textclf_logreg\n",
      "copying textclf_logreg\\tfidf.joblib -> build\\lib\\textclf_logreg\n",
      "installing to build\\bdist.win-amd64\\wheel\n",
      "running install\n",
      "running install_lib\n",
      "creating build\\bdist.win-amd64\n",
      "creating build\\bdist.win-amd64\\wheel\n",
      "creating build\\bdist.win-amd64\\wheel\\textclf_logreg\n",
      "copying build\\lib\\textclf_logreg\\model.joblib -> build\\bdist.win-amd64\\wheel\\.\\textclf_logreg\n",
      "copying build\\lib\\textclf_logreg\\tfidf.joblib -> build\\bdist.win-amd64\\wheel\\.\\textclf_logreg\n",
      "copying build\\lib\\textclf_logreg\\__init__.py -> build\\bdist.win-amd64\\wheel\\.\\textclf_logreg\n",
      "running install_egg_info\n",
      "Copying textclf_logreg.egg-info to build\\bdist.win-amd64\\wheel\\.\\textclf_logreg-0.1.0-py3.13.egg-info\n",
      "running install_scripts\n",
      "creating build\\bdist.win-amd64\\wheel\\textclf_logreg-0.1.0.dist-info\\WHEEL\n",
      "creating 'wheel_logreg\\dist\\textclf_logreg-0.1.0-py3-none-any.whl' and adding 'build\\bdist.win-amd64\\wheel' to it\n",
      "adding 'textclf_logreg/__init__.py'\n",
      "adding 'textclf_logreg/model.joblib'\n",
      "adding 'textclf_logreg/tfidf.joblib'\n",
      "adding 'textclf_logreg-0.1.0.dist-info/METADATA'\n",
      "adding 'textclf_logreg-0.1.0.dist-info/WHEEL'\n",
      "adding 'textclf_logreg-0.1.0.dist-info/top_level.txt'\n",
      "adding 'textclf_logreg-0.1.0.dist-info/RECORD'\n",
      "removing build\\bdist.win-amd64\\wheel\n",
      "\n",
      "Wheel generado: D:\\OneDrive\\Documents\\MAIA\\Semestre 4\\Desarrollo de Soluciones\\Microproyecto\\Clasificacion-de-textos-medicos\\EXPLORACION\\wheel_logreg\\wheel_logreg\\dist\\textclf_logreg-0.1.0-py3-none-any.whl\n"
     ]
    }
   ],
   "source": [
    "# === Build de un wheel mínimo para UN modelo ya entrenado (ej: logreg) ===\n",
    "# Requisitos previos en el entorno: pip install wheel setuptools joblib\n",
    "import sys, shutil, subprocess, textwrap\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "# --- Selecciona el modelo ya ENTRENADO y el vectorizador TF-IDF ---\n",
    "pkg_key   = \"logreg\"   # cambia a \"svm\" / \"naive_bayes\" / \"xgboost\" si quieres\n",
    "model_obj = logreg     # objeto del modelo ya entrenado\n",
    "vec_obj   = vec        # TfidfVectorizer ya entrenado\n",
    "\n",
    "# --- Estructura del paquete ---\n",
    "root = Path(f\"wheel_{pkg_key}\")\n",
    "if root.exists():\n",
    "    shutil.rmtree(root)\n",
    "pkg_name = f\"textclf_{pkg_key}\"\n",
    "pkg_dir  = root / pkg_name\n",
    "dist_dir = root / \"dist\"\n",
    "pkg_dir.mkdir(parents=True)\n",
    "dist_dir.mkdir(parents=True)\n",
    "\n",
    "# --- Artefactos dentro del paquete ---\n",
    "joblib.dump(vec_obj,   pkg_dir / \"tfidf.joblib\")\n",
    "joblib.dump(model_obj, pkg_dir / \"model.joblib\")\n",
    "\n",
    "# --- __init__.py con API simple ---\n",
    "init_code = \"\"\"\n",
    "import joblib\n",
    "from importlib.resources import files\n",
    "\n",
    "_VEC = joblib.load(files(__package__) / \"tfidf.joblib\")\n",
    "_MDL = joblib.load(files(__package__) / \"model.joblib\")\n",
    "\n",
    "def predict(texts):\n",
    "    X = _VEC.transform([str(t) for t in texts])\n",
    "    if hasattr(_MDL, \"predict_proba\"):\n",
    "        scores = _MDL.predict_proba(X)[:, 1]\n",
    "    elif hasattr(_MDL, \"decision_function\"):\n",
    "        from scipy.special import expit\n",
    "        scores = expit(_MDL.decision_function(X))\n",
    "    else:\n",
    "        scores = [0.5] * X.shape[0]\n",
    "    import numpy as np\n",
    "    labels = (np.asarray(scores) >= 0.5).astype(int).tolist()\n",
    "    return {\"labels\": labels, \"scores\": [float(s) for s in scores]}\n",
    "\"\"\".strip()\n",
    "(pkg_dir / \"__init__.py\").write_text(init_code, encoding=\"utf-8\")\n",
    "\n",
    "# --- setup.cfg + setup.py mínimos (setuptools declara el package y los data) ---\n",
    "setup_cfg = f\"\"\"\n",
    "[metadata]\n",
    "name = {pkg_name}\n",
    "version = 0.1.0\n",
    "description = Minimal wheel with TF-IDF + {pkg_key} model\n",
    "\n",
    "[options]\n",
    "packages = find:\n",
    "include_package_data = True\n",
    "install_requires =\n",
    "    scikit-learn\n",
    "    joblib\n",
    "    numpy\n",
    "    scipy\n",
    "python_requires = >=3.9\n",
    "\n",
    "[options.package_data]\n",
    "{pkg_name} = *.joblib\n",
    "\"\"\"\n",
    "(root / \"setup.cfg\").write_text(textwrap.dedent(setup_cfg).strip(), encoding=\"utf-8\")\n",
    "(root / \"setup.py\").write_text(\"from setuptools import setup; setup()\", encoding=\"utf-8\")\n",
    "(root / \"MANIFEST.in\").write_text(f\"recursive-include {pkg_name} *.joblib\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# --- Asegura herramientas de build ---\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"wheel\", \"setuptools>=61.0\"], check=True)\n",
    "\n",
    "# --- Construir wheel con setuptools (lo deja en dist/) ---\n",
    "proc = subprocess.run(\n",
    "    [sys.executable, \"setup.py\", \"bdist_wheel\", \"-d\", str(dist_dir)],\n",
    "    cwd=str(root),\n",
    "    text=True,\n",
    "    capture_output=True\n",
    ")\n",
    "print(proc.stdout)\n",
    "if proc.returncode != 0:\n",
    "    print(\"=== STDERR ===\")\n",
    "    print(proc.stderr)\n",
    "    raise RuntimeError(\"Fallo al construir el wheel\")\n",
    "\n",
    "# --- Localizar el wheel (dist/ o fallback recursivo) ---\n",
    "wheels = list(dist_dir.glob(\"*.whl\"))\n",
    "if not wheels:\n",
    "    wheels = list(root.rglob(\"*.whl\"))  # fallback por si alguna tool lo deja en otro lado\n",
    "if not wheels:\n",
    "    raise RuntimeError(\"No se generó ningún .whl; revisa el log arriba.\")\n",
    "\n",
    "print(\"Wheel generado:\", wheels[0].resolve())\n",
    "# Instálalo con: pip install <ruta mostrada>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4999f-70bc-4d3e-85eb-580253bb5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "def export_code_cells():\n",
    "    from IPython import get_ipython\n",
    "    cells = get_ipython().user_ns['In']\n",
    "    code = '\\n\\n'.join([c for c in cells if c.strip()])\n",
    "    return Markdown(f'```python\\n{code}\\n```')\n",
    "\n",
    "#export_code_cells()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
